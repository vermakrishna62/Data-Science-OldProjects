{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512c5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742c2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\n",
    "    'Well done',\n",
    "    'What are u doing',\n",
    "    'Good Night',\n",
    "    'Looking like a woaw',\n",
    "    'Arabian Nights',\n",
    "    'Gadar 2',\n",
    "    'India India',\n",
    "    'Bharat Mata ki Jai',\n",
    "    'Jai Shri Ram'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a267d",
   "metadata": {},
   "source": [
    "## Two Techniques of vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63673397",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9753edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7f1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f23d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vector.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094dcffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['arabian', 'are', 'bharat', 'doing', 'done', 'gadar', 'good',\n",
       "       'india', 'jai', 'ki', 'like', 'looking', 'mata', 'night', 'nights',\n",
       "       'ram', 'shri', 'well', 'what', 'woaw'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad388a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af765359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabian' 'are' 'bharat' 'doing' 'done' 'gadar' 'good' 'india' 'jai' 'ki'\n",
      " 'like' 'looking' 'mata' 'night' 'nights' 'ram' 'shri' 'well' 'what'\n",
      " 'woaw']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vector.get_feature_names_out())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5bc16",
   "metadata": {},
   "source": [
    "### Integer Encoding - Used in Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f156c80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 23:16:30.380026: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 23:16:30.463406: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 23:16:30.464545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 23:16:32.177445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a8ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5098230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6722a8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'india': 1,\n",
       " 'jai': 2,\n",
       " 'well': 3,\n",
       " 'done': 4,\n",
       " 'what': 5,\n",
       " 'are': 6,\n",
       " 'u': 7,\n",
       " 'doing': 8,\n",
       " 'good': 9,\n",
       " 'night': 10,\n",
       " 'looking': 11,\n",
       " 'like': 12,\n",
       " 'a': 13,\n",
       " 'woaw': 14,\n",
       " 'arabian': 15,\n",
       " 'nights': 16,\n",
       " 'gadar': 17,\n",
       " '2': 18,\n",
       " 'bharat': 19,\n",
       " 'mata': 20,\n",
       " 'ki': 21,\n",
       " 'shri': 22,\n",
       " 'ram': 23}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47db451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('well', 1),\n",
       "             ('done', 1),\n",
       "             ('what', 1),\n",
       "             ('are', 1),\n",
       "             ('u', 1),\n",
       "             ('doing', 1),\n",
       "             ('good', 1),\n",
       "             ('night', 1),\n",
       "             ('looking', 1),\n",
       "             ('like', 1),\n",
       "             ('a', 1),\n",
       "             ('woaw', 1),\n",
       "             ('arabian', 1),\n",
       "             ('nights', 1),\n",
       "             ('gadar', 1),\n",
       "             ('2', 1),\n",
       "             ('india', 2),\n",
       "             ('bharat', 1),\n",
       "             ('mata', 1),\n",
       "             ('ki', 1),\n",
       "             ('jai', 2),\n",
       "             ('shri', 1),\n",
       "             ('ram', 1)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd8d7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequence = tokenizer.texts_to_sequences(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0416b4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4],\n",
       " [5, 6, 7, 8],\n",
       " [9, 10],\n",
       " [11, 12, 13, 14],\n",
       " [15, 16],\n",
       " [17, 18],\n",
       " [1, 1],\n",
       " [19, 20, 21, 2],\n",
       " [2, 22, 23]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "139d2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the sequence\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21e6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences=text_sequence,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04563d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  0,  0],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10,  0,  0],\n",
       "       [11, 12, 13, 14],\n",
       "       [15, 16,  0,  0],\n",
       "       [17, 18,  0,  0],\n",
       "       [ 1,  1,  0,  0],\n",
       "       [19, 20, 21,  2],\n",
       "       [ 2, 22, 23,  0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8046b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
